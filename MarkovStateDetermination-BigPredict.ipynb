{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import matplotlib as plot\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import itertools as it\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from keras.utils import to_categorical\n",
    "#from keras.models import Sequential\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import json\n",
    "\n",
    "enc = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luke\\AppData\\Local\\Temp\\ipykernel_14068\\1992295156.py:5: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  DOT_df = pd.read_csv('2025-01-27-2017-09-07_DOT-USDT_1H_ohlc_M.csv')\n"
     ]
    }
   ],
   "source": [
    "BTC_df = pd.read_csv('20250202-20170908_BTC-USDT_1D_okx_ohlc_M.csv')\n",
    "BNB_df = pd.read_csv('20250127-20170907_BNB-USDT_1H_ohlc_M.csv')\n",
    "DOGE_df = pd.read_csv('20250202-20170908_DOGE-USDT_1D_okx_ohlc_M.csv')\n",
    "XRP_df = pd.read_csv('20250202-20170908_XRP-USDT_1D_okx_ohlc_M.csv')\n",
    "DOT_df = pd.read_csv('2025-01-27-2017-09-07_DOT-USDT_1H_ohlc_M.csv')\n",
    "SHIB_df = pd.read_csv('20250202-20170908_SHIB-USDT_1D_okx_ohlc_M.csv')\n",
    "#df['Date'] = pd.to_datetime(df['timestamp'], format='%m/%d/%Y %I:%M:%S %p')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RSI CALC\n",
    "def get_up_or_down(df, period):\n",
    "    for i in range(len(df)):\n",
    "        if i > 0:\n",
    "            if df.iloc[i]['close'] >= df.iloc[i-1]['close']:\n",
    "                df.at[i, 'gain_'+str(period)] = df.iloc[i]['close'] - df.iloc[i-1]['close']\n",
    "                df.at[i, 'loss_'+str(period)] = 0\n",
    "            elif df.iloc[i]['close'] < df.iloc[i-1]['close']:\n",
    "                df.at[i, 'loss_'+str(period)] = df.iloc[i-1]['close'] - df.iloc[i]['close']\n",
    "                df.at[i, 'gain_'+str(period)] = 0\n",
    "            else:\n",
    "                df.at[i, 'gain_'+str(period)] = 0\n",
    "                df.at[i, 'loss_'+str(period)] = 0\n",
    "    return df\n",
    "\n",
    "def get_up_or_down_bin(df, offset):\n",
    "    for i in range(len(df)):\n",
    "        if i > 0:\n",
    "            if df.iloc[i]['close'] >= df.iloc[i-offset]['close']:\n",
    "                df.at[i, 'updown_'+str(offset)] = 1\n",
    "            elif df.iloc[i]['close'] < df.iloc[i-offset]['close']:\n",
    "                df.at[i, 'updown_'+str(offset)] = -1                \n",
    "            else:\n",
    "                df.at[i, 'updown_'+str(offset)] = 0\n",
    "    return df\n",
    "  \n",
    "def get_relative_strength_index(df, period):\n",
    "    try:\n",
    "        df['Date'] = pd.to_datetime(df['timestamp'])\n",
    "    except:\n",
    "        df['Date'] = pd.to_datetime(df['timestamp'], format='%m/%d/%Y %I:%M:%S %p', errors='coerce')\n",
    "    #df['Date'] = pd.to_datetime(df['timestamp'], format='%m/%d/%Y %I:%M:%S %p')\n",
    "    #df['Date'] = pd.to_datetime(df['timestamp'], format='%m/%d/%Y %I:%M:%S %p')\n",
    "    #df['Date'] = pd.to_datetime(df['timestamp'], format='%m/%d/%Y %I:%M:%S %p', errors='coerce')\n",
    "\n",
    "    df.set_index(df['Date'])\n",
    "    df = get_up_or_down(df, period)\n",
    "    return df\n",
    "\n",
    "def get_average_gains(df, period):\n",
    "    for i in range(len(df)):\n",
    "        n, up, down = 0, 0, 0\n",
    "        if i == period:\n",
    "            while n < period:\n",
    "                if df.iloc[i-n]['gain_'+str(period)] > 0:\n",
    "                    up += df.iloc[i-n]['gain_'+str(period)]\n",
    "                elif df.iloc[i-n]['loss_'+str(period)] > 0:\n",
    "                    down += df.iloc[i-n]['loss_'+str(period)]\n",
    "                else:\n",
    "                    up += 0\n",
    "                    down += 0\n",
    "                n += 1\n",
    "            df.at[i, 'ag_'+str(period)] = up/period\n",
    "            df.at[i, 'al_'+str(period)] = down/period\n",
    "        elif i > period:\n",
    "            df.at[i, 'ag_'+str(period)] = (df.iloc[i-1]['ag_'+str(period)] * (period - 1) + df.iloc[i]['gain_'+str(period)])/period\n",
    "            df.at[i, 'al_'+str(period)] = (df.iloc[i-1]['al_'+str(period)] * (period - 1) + df.iloc[i]['loss_'+str(period)])/period\n",
    "            df['ag_'+str(period)] = df['ag_'+str(period)].fillna(0)\n",
    "            df['al_'+str(period)] = df['al_'+str(period)].fillna(0)\n",
    "    return df\n",
    "\n",
    "def get_relative_strength(df, period):\n",
    "    df = get_relative_strength_index(df,period)\n",
    "    df = get_average_gains(df, period)\n",
    "    rs_col = f'rs_{period}' #added\n",
    "    rsi_col = f'rsi_{period}'#added\n",
    "    df[rs_col] = np.nan#added\n",
    "    df[rsi_col] = np.nan    #added\n",
    "    #for i in range(len(df)):\n",
    "    '''\n",
    "    if i >= period:\n",
    "            df.at[i, 'rs_'+str(period)] = df.iloc[i]['ag_'+str(period)]/df.iloc[i]['al_'+str(period)]\n",
    "            df.at[i, 'rsi_'+str(period)] = (100-(100/(1+df.iloc[i]['rs_'+str(period)])))\n",
    "    '''\n",
    "    for i in range(len(df)):\n",
    "        if i >= period and df.iloc[i]['al_'+str(period)] != 0:\n",
    "            df.at[i, rs_col] = df.iloc[i]['ag_'+str(period)] / df.iloc[i]['al_'+str(period)]\n",
    "            df.at[i, rsi_col] = 100 - (100 / (1 + df.at[i, rs_col]))\n",
    "        elif i >= period:\n",
    "            df.at[i, rs_col] = 0\n",
    "            df.at[i, rsi_col] = 100\n",
    "\n",
    "    return df\n",
    "\n",
    "##MONEY FLOW\n",
    "def get_typical_price(high, low, close):\n",
    "    typical_price = (high+low+close/3)\n",
    "    return typical_price\n",
    "\n",
    "def get_raw_money_flow(typical_price, volume):\n",
    "    money_flow = typical_price * volume\n",
    "    return money_flow\n",
    "\n",
    "def get_money_flow_ratio(money_flow, window=14):\n",
    "    signal = np.where(money_flow > money_flow.shift(1), 1, np.where(money_flow < money_flow.shift(1), -1, 0))\n",
    "    money_flow_s = money_flow * signal\n",
    "    \n",
    "    money_flow_positive = money_flow_s.rolling(window).apply(lambda x: np.sum(np.where(x >= 0.0, x, 0.0)), raw=True)\n",
    "    money_flow_negative = abs(money_flow_s.rolling(window).apply(lambda x: np.sum(np.where(x < 0.0, x, 0.0)), raw=True))\n",
    "    \n",
    "    money_flow_ratio = money_flow_positive / money_flow_negative\n",
    "    \n",
    "    return money_flow_ratio\n",
    "\n",
    "def get_money_flow_index(money_flow_ratio):\n",
    "    money_flow_index = 100. - 100./(1. + money_flow_ratio)\n",
    "    return money_flow_index\n",
    "\n",
    "def money_flow_index(high, low, close, volume, window=14):\n",
    "    mfr = get_money_flow_ratio((high+low+close/3) * volume, window)\n",
    "    mfi = 100. - 100./(1. + mfr)\n",
    "    return mfi\n",
    "\n",
    "#Choppiness index\n",
    "def get_ci(high, low, close, lookback):\n",
    "    tr1 = pd.DataFrame(high - low).rename(columns = {0:'tr1'})\n",
    "    tr2 = pd.DataFrame(abs(high - close.shift(1))).rename(columns = {0:'tr2'})\n",
    "    tr3 = pd.DataFrame(abs(low - close.shift(1))).rename(columns = {0:'tr3'})\n",
    "    frames = [tr1, tr2, tr3]\n",
    "    tr = pd.concat(frames, axis = 1, join = 'inner').dropna().max(axis = 1)\n",
    "    atr = tr.rolling(1).mean()\n",
    "    highh = high.rolling(lookback).max()\n",
    "    lowl = low.rolling(lookback).min()\n",
    "    ci = 100 * np.log10((atr.rolling(lookback).sum()) / (highh - lowl)) / np.log10(lookback)\n",
    "    return ci\n",
    "\n",
    "#Feature Extraction\n",
    "def feature_extraction(df, time_steps_arr):\n",
    "    df['range'] = df['high'] - df['low']\n",
    "    df['range%'] = df['range']/df['close']\n",
    "    df['obv'] = (np.sign(df['close'].diff()) * df['volume_ccy']).fillna(0).cumsum()    \n",
    "    df['return'] = df['close'].pct_change() \n",
    "    \n",
    "    features_list = ['range', 'range%', 'obv', 'return']\n",
    "    for time in time_steps_arr:\n",
    "        #df['return_'+str(time)] = (df.close / df.close.shift(time)) - 1\n",
    "        df['return_'+str(time)] = (df['close'] / df['close'].shift(time)) - 1\n",
    "        df = get_relative_strength(df, time)\n",
    "        df = get_up_or_down_bin(df, time)\n",
    "        df['std_'+str(time)] = df['return_'+str(time)].rolling(time).std()\n",
    "        df['ma_'+str(time)] = df['close'].rolling(time).mean()\n",
    "        df['mfi_'+str(time)]= money_flow_index(df['high'], df['low'], df['close'], df['volume_ccy'], time)\n",
    "        df['ma_'+str(time)] = df['close'].rolling(time).mean()\n",
    "        df['avgvolm_'+str(time)] = df['volume_ccy'].rolling(time).mean()\n",
    "        df['avgvolty_'+str(time)] = df['std_'+str(time)].rolling(time).mean()\n",
    "        df['rtrend_'+str(time)] = df['updown_'+str(time)].rolling(time).sum()\n",
    "        df['ci_'+str(time)] = get_ci(df['high'], df['low'], df['close'], time)\n",
    "        \n",
    "        features_list.extend(['return_' + str(time), 'rs_' + str(time), 'updown_' + str(time),'std_' + str(time), 'ma_' + str(time), 'mfi_' + str(time),'avgvolm_' + str(time), 'avgvolty_' + str(time), 'rtrend_' + str(time),'ci_' + str(time)])\n",
    "    return df, features_list\n",
    "\n",
    "def training_states_shift(df, time_steps_arr):\n",
    "    for time in time_steps_arr:\n",
    "        df['mStateSt_'+str(time)] = df.m_st.shift(time)\n",
    "        df['mStateMid_'+str(time)] = df.m_mt.shift(time)\n",
    "        df['mStateLt_'+str(time)] = df.m_lt.shift(time)\n",
    "        \n",
    "        training_list = []\n",
    "        training_list.append('mStateSt_'+str(time))\n",
    "        training_list.append('mStateMid_'+str(time))\n",
    "        training_list.append('mStateLt_'+str(time))\n",
    "    return df, training_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BTC_df.columns = BTC_df.columns.str.strip().str.lower()\n",
    "\n",
    "'''\n",
    "BTC_df['markov_mt'] = BTC_df['m_mt'].astype('str') \n",
    "BTC_df['markov_mt'] = enc.fit_transform(BTC_df['m_mt'])\n",
    "\n",
    "BTC_df['markov_st'] = BTC_df['m_st'].astype('str')\n",
    "BTC_df['markov_st'] = enc.fit_transform(BTC_df['m_st'])\n",
    "\n",
    "BTC_df['markov_lt'] = BTC_df['m_lt'].astype('str')\n",
    "BTC_df['markov_lt'] = enc.fit_transform(BTC_df['m_lt'])\n",
    "\n",
    "\n",
    "XRP_df['markov_mt'] = XRP_df['m_mt'].astype('str') \n",
    "XRP_df['markov_mt'] = enc.fit_transform(XRP_df['m_mt'])\n",
    "\n",
    "XRP_df['markov_st'] = XRP_df['m_st'].astype('str')\n",
    "XRP_df['markov_st'] = enc.fit_transform(XRP_df['m_st'])\n",
    "\n",
    "XRP_df['markov_lt'] = XRP_df['m_lt'].astype('str')\n",
    "XRP_df['markov_lt'] = enc.fit_transform(XRP_df['m_lt'])\n",
    "\n",
    "\n",
    "BNB_df['markov_mt'] = BNB_df['m_mt'].astype('str') \n",
    "BNB_df['markov_mt'] = enc.fit_transform(BNB_df['m_mt'])\n",
    "\n",
    "BNB_df['markov_st'] = BNB_df['m_st'].astype('str')\n",
    "BNB_df['markov_st'] = enc.fit_transform(BNB_df['m_st'])\n",
    "\n",
    "BNB_df['markov_lt'] = BNB_df['m_lt'].astype('str')\n",
    "BNB_df['markov_lt'] = enc.fit_transform(BNB_df['m_lt'])\n",
    "\n",
    "\n",
    "DOGE_df['markov_mt'] = DOGE_df['m_mt'].astype('str') \n",
    "DOGE_df['markov_mt'] = enc.fit_transform(DOGE_df['m_mt'])\n",
    "\n",
    "DOGE_df['markov_st'] = DOGE_df['m_st'].astype('str')\n",
    "DOGE_df['markov_st'] = enc.fit_transform(DOGE_df['m_st'])\n",
    "\n",
    "DOGE_df['markov_lt'] = DOGE_df['m_lt'].astype('str')\n",
    "DOGE_df['markov_lt'] = enc.fit_transform(DOGE_df['m_lt'])\n",
    "'''\n",
    "\n",
    "#time_periods = (2,3,4,5,6,7,8,9,10,12,15,17,20,25,30,35,40,45,50,60,70,80,90,100,150,200)\n",
    "time_periods = (2,3,5,7,10,14,19,25,35,50,100,200)\n",
    "#time_periods = (2,15,50,100)\n",
    "#time_periods = (2,15)\n",
    "features_list = []\n",
    "BTC_df, features_list = feature_extraction(BTC_df, time_periods)\n",
    "BTC_df, training_list = training_states_shift(BTC_df, time_periods)\n",
    "\n",
    "XRP_df = feature_extraction(XRP_df, time_periods)[0]\n",
    "XRP_df = training_states_shift(XRP_df, time_periods)[0]\n",
    "\n",
    "BNB_df = feature_extraction(BNB_df, time_periods)[0]\n",
    "BNB_df = training_states_shift(BNB_df, time_periods)[0]\n",
    "\n",
    "DOGE_df = feature_extraction(DOGE_df, time_periods)[0]\n",
    "DOGE_df = training_states_shift(DOGE_df, time_periods)[0]\n",
    "\n",
    "#print(features_list)\n",
    "\n",
    "'''\n",
    "stack_df = BTC_df.append(XRP_df)\n",
    "stack_df = stack_df.append(BNB_df)\n",
    "stack_df = stack_df.append(DOGE_df)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['timestamp', 'open', 'high', 'low', 'close', 'volume', 'volume_ccy', 'volCcyQuote', 'm_mt', 'm_st', 'm_lt', 'markov_mt', 'markov_st', 'markov_lt', 'range', 'range%', 'obv', 'return', 'return_2', 'Date', 'loss_2', 'gain_2', 'ag_2', 'al_2', 'rs_2', 'rsi_2', 'updown_2', 'std_2', 'ma_2', 'mfi_2', 'avgvolm_2', 'avgvolty_2', 'rtrend_2', 'ci_2', 'return_15', 'loss_15', 'gain_15', 'ag_15', 'al_15', 'rs_15', 'rsi_15', 'updown_15', 'std_15', 'ma_15', 'mfi_15', 'avgvolm_15', 'avgvolty_15', 'rtrend_15', 'ci_15', 'mStateSt_2', 'mStateMid_2', 'mStateLt_2', 'mStateSt_15', 'mStateMid_15', 'mStateLt_15']\n",
      "['timestamp', 'open', 'high', 'low', 'close', 'volume', 'volume_ccy', 'volccyquote', 'm_mt', 'm_st', 'm_lt', 'markov_mt', 'markov_st', 'markov_lt', 'range', 'range%', 'obv', 'return', 'return_2', 'Date', 'gain_2', 'loss_2', 'ag_2', 'al_2', 'rs_2', 'rsi_2', 'updown_2', 'std_2', 'ma_2', 'mfi_2', 'avgvolm_2', 'avgvolty_2', 'rtrend_2', 'ci_2', 'return_15', 'gain_15', 'loss_15', 'ag_15', 'al_15', 'rs_15', 'rsi_15', 'updown_15', 'std_15', 'ma_15', 'mfi_15', 'avgvolm_15', 'avgvolty_15', 'rtrend_15', 'ci_15', 'mStateSt_2', 'mStateMid_2', 'mStateLt_2', 'mStateSt_15', 'mStateMid_15', 'mStateLt_15']\n",
      "['timestamp', 'open', 'high', 'low', 'close', 'volume', 'volume_ccy', 'volCcyQuote', 'm_mt', 'm_st', 'm_lt', 'markov_mt', 'markov_st', 'markov_lt', 'range', 'range%', 'obv', 'return', 'return_2', 'Date', 'loss_2', 'gain_2', 'ag_2', 'al_2', 'rs_2', 'rsi_2', 'updown_2', 'std_2', 'ma_2', 'mfi_2', 'avgvolm_2', 'avgvolty_2', 'rtrend_2', 'ci_2', 'return_15', 'loss_15', 'gain_15', 'ag_15', 'al_15', 'rs_15', 'rsi_15', 'updown_15', 'std_15', 'ma_15', 'mfi_15', 'avgvolm_15', 'avgvolty_15', 'rtrend_15', 'ci_15', 'mStateSt_2', 'mStateMid_2', 'mStateLt_2', 'mStateSt_15', 'mStateMid_15', 'mStateLt_15']\n",
      "['timestamp', 'open', 'high', 'low', 'close', 'volume', 'volume_ccy', 'volCcyQuote', 'm_mt', 'm_st', 'm_lt', 'markov_mt', 'markov_st', 'markov_lt', 'range', 'range%', 'obv', 'return', 'return_2', 'Date', 'gain_2', 'loss_2', 'ag_2', 'al_2', 'rs_2', 'rsi_2', 'updown_2', 'std_2', 'ma_2', 'mfi_2', 'avgvolm_2', 'avgvolty_2', 'rtrend_2', 'ci_2', 'return_15', 'gain_15', 'loss_15', 'ag_15', 'al_15', 'rs_15', 'rsi_15', 'updown_15', 'std_15', 'ma_15', 'mfi_15', 'avgvolm_15', 'avgvolty_15', 'rtrend_15', 'ci_15', 'mStateSt_2', 'mStateMid_2', 'mStateLt_2', 'mStateSt_15', 'mStateMid_15', 'mStateLt_15']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "next steps\n",
    "-merge the columns/format for all training data\n",
    "-label more data\n",
    "-add in funding rates, implied vols, spx, gold, qqq, silver, copper, tbill rate, fed decision day, money supply (M2)\n",
    "-stack the training data\n",
    "-set this up as training, validation, prediction\n",
    "-try LR, RF, and NN\n",
    "-research how to identify rangebound markets' peaks and troughs\n",
    "-figure out how to re-apply predicted markov states to be fed into training\n",
    "-run this three times: try both \n",
    "    1) predict short term, then 2) mid term then 3) long term\n",
    "    1) predict long term, then 2) mid term then 3) short term\n",
    "    and see which predicts better\n",
    "-apply Kelly Criterion\n",
    "-research stop losses\n",
    "\n",
    "\"\"\"\n",
    "#print(list(XRP_df.columns))\n",
    "#print(list(BTC_df.columns))\n",
    "#print(features_list)\n",
    "#print(type(features_list))\n",
    "#print(type(training_list))\n",
    "\n",
    "print(list(XRP_df.columns))\n",
    "print(list(BTC_df.columns))\n",
    "print(list(BNB_df.columns))\n",
    "print(list(DOGE_df.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m_mt up\n",
    "#m_mt down\n",
    "#m_mt flat\n",
    "\n",
    "all_cols = BTC_df.columns.tolist()\n",
    "features_list.extend(training_list)\n",
    "features_list.append('m_mt_up')\n",
    "drop_list = [item for item in all_cols if item not in features_list]\n",
    "\n",
    "BTC_df = BTC_df.reset_index(drop=True)\n",
    "XRP_df = XRP_df.reset_index(drop=True)\n",
    "BNB_df = BNB_df.reset_index(drop=True)\n",
    "DOGE_df = DOGE_df.reset_index(drop=True)\n",
    "result = pd.concat([BTC_df, XRP_df, BNB_df, DOGE_df], axis=0)\n",
    "\n",
    "dataCleaned = result.drop(drop_list, axis=1)\n",
    "dataCleaned = dataCleaned.dropna()\n",
    "\n",
    "y = dataCleaned['m_mt up'] # Target variable\n",
    "X = dataCleaned.drop('m_mt up', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=99999, random_state=42)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "model = LogisticRegression(random_state=42, max_iter=99999) # Initialize the model\n",
    "model.fit(X_train, y_train) # Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['markov_mt', 'range', 'range%', 'obv', 'return', 'return_2', 'rs_2', 'updown_2', 'std_2', 'ma_2', 'mfi_2', 'avgvolm_2', 'avgvolty_2', 'rtrend_2', 'ci_2', 'return_15', 'rs_15', 'updown_15', 'std_15', 'ma_15', 'mfi_15', 'avgvolm_15', 'avgvolty_15', 'rtrend_15', 'ci_15', 'mStateSt_15', 'mStateMid_15', 'mStateLt_15', 'volCcyQuote']\n"
     ]
    }
   ],
   "source": [
    "print(list(dataCleaned.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.46252478519497686\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       296\n",
      "           1       0.27      0.18      0.22      1503\n",
      "           2       0.57      0.73      0.64      3946\n",
      "           3       0.23      0.18      0.20      1820\n",
      "\n",
      "    accuracy                           0.46      7565\n",
      "   macro avg       0.27      0.27      0.27      7565\n",
      "weighted avg       0.40      0.46      0.43      7565\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luke\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Luke\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Luke\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#classification algorithms \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
